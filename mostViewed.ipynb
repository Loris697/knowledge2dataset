{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Pacchetti"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZE70Dc5EdjSK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "425e98fc-7693-4f49-a8f8-313647178f21",
    "ExecuteTime": {
     "end_time": "2024-05-27T22:46:19.939177Z",
     "start_time": "2024-05-27T22:46:19.936469Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variabili globali"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Variabili globali\n",
    "WIKIPEDIA_API_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "nentities = 10000\n",
    "BATCH_SIZE = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T22:46:19.948529Z",
     "start_time": "2024-05-27T22:46:19.946529Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Moduli"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def process_batch(titles_batch, api_url=\"https://en.wikipedia.org/w/api.php\"):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": \"|\".join(titles_batch),\n",
    "        \"prop\": \"pageprops\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        pages = response.json().get('query', {}).get('pages', {})\n",
    "        batch_entities = {}\n",
    "        for page_id, page_info in pages.items():\n",
    "            pageprops = page_info.get('pageprops', {})\n",
    "            wikidata_id = pageprops.get('wikibase_item')\n",
    "            if wikidata_id:\n",
    "                batch_entities[page_info['title']] = wikidata_id\n",
    "        return batch_entities\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        return {}  # Return an empty dict in case of failure\n",
    "    \n",
    "def fetch_wikidata_ids(most_viewed_pages, batch_size=50, api_url=\"https://en.wikipedia.org/w/api.php\"):\n",
    "    entities = {}\n",
    "    titles_batch = []\n",
    "\n",
    "    for page in most_viewed_pages:\n",
    "        titles_batch.append(page['article'])\n",
    "        if len(titles_batch) >= batch_size:\n",
    "            entities.update(process_batch(titles_batch, api_url))\n",
    "            titles_batch = []  # Reset the batch\n",
    "\n",
    "    if titles_batch:  # Process any remaining titles\n",
    "        entities.update(process_batch(titles_batch, api_url))\n",
    "    return entities\n",
    "\n",
    "def fetch_most_viewed_pages(total_pages, api_url=\"https://en.wikipedia.org/w/api.php\"):\n",
    "    limit = 500\n",
    "    fetched_pages = []\n",
    "\n",
    "    for i in range(0, total_pages, limit):\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"list\": \"mostviewed\",\n",
    "            \"pvimlimit\": min(limit, total_pages - i)\n",
    "        }\n",
    "\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if 'query' in response_data and 'mostviewed' in response_data['query']:\n",
    "            fetched_pages.extend(response_data['query']['mostviewed'])\n",
    "        else:\n",
    "            break  # Exit loop if no more data is available\n",
    "\n",
    "    return fetched_pages\n",
    "\n",
    "def get_relations_batch(wikidata_ids, batch_size=50, api_url=\"https://www.wikidata.org/w/api.php\"):\n",
    "    relations = {}\n",
    "    for start in range(0, len(wikidata_ids), batch_size):\n",
    "        end = start + batch_size\n",
    "        batch = wikidata_ids[start:end]\n",
    "        wikidata_ids_str = \"|\".join(batch)\n",
    "\n",
    "        print(f\"Processing batch {start // batch_size + 1} out of {len(wikidata_ids) // batch_size + 1}\")\n",
    "\n",
    "        params = {\n",
    "            \"action\": \"wbgetentities\",\n",
    "            \"format\": \"json\",\n",
    "            \"ids\": wikidata_ids_str,\n",
    "            \"props\": \"claims\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(api_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: Received status code {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = response.json().get('entities', {})\n",
    "        except ValueError:\n",
    "            print(\"Error: Unable to parse JSON response\")\n",
    "            continue\n",
    "\n",
    "        for wikidata_id in batch:\n",
    "            if wikidata_id in data:\n",
    "                claims = data[wikidata_id].get('claims', {})\n",
    "                relations[wikidata_id] = claims\n",
    "            else:\n",
    "                print(f\"Warning: No data found for Wikidata ID {wikidata_id}\")\n",
    "\n",
    "    return relations\n",
    "\n",
    "def query(request):\n",
    "    lastContinue = {}\n",
    "    while True:\n",
    "        # Clone original request\n",
    "        req = request.copy()\n",
    "        # Modify it with the values returned in the 'continue' section of the last result.\n",
    "        req.update(lastContinue)\n",
    "\n",
    "        user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "\n",
    "        result = requests.get('https://wikimedia.org/api/rest_v1/metrics/pageviews/top/en.wikipedia/all-access/2024/01/01', headers={'User-Agent': user_agent}).json()\n",
    "\n",
    "        if 'error' in result:\n",
    "            raise Exception(result['error'])\n",
    "        if 'warnings' in result:\n",
    "            print(result['warnings'])\n",
    "        if 'items' in result:\n",
    "            yield result['items'][0]['articles']  # The articles are in 'items' -> first element -> 'articles'\n",
    "        if 'continue' not in result:\n",
    "            break\n",
    "        lastContinue = result['continue']\n",
    "\n",
    "def most_viewed():\n",
    "    request = {}\n",
    "\n",
    "    res = query(request)\n",
    "    nl = list()\n",
    "    for r in res:\n",
    "        nl.extend(r)\n",
    "\n",
    "    return nl"
   ],
   "metadata": {
    "id": "mhqmn2j9EwTU",
    "ExecuteTime": {
     "end_time": "2024-05-27T22:46:19.966470Z",
     "start_time": "2024-05-27T22:46:19.957222Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def query(date):\n",
    "    url = f'https://wikimedia.org/api/rest_v1/metrics/pageviews/top/en.wikipedia/all-access/{date}'\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "\n",
    "    result = requests.get(url, headers={'User-Agent': user_agent}).json()\n",
    "\n",
    "    if 'error' in result:\n",
    "        raise Exception(result['error'])\n",
    "    if 'warnings' in result:\n",
    "        print(result['warnings'])\n",
    "    if 'items' in result:\n",
    "        return result['items'][0]['articles']\n",
    "    return []\n",
    "\n",
    "def most_viewed(n):\n",
    "    unique_articles = {}\n",
    "    date = datetime.strptime(\"2024-01-01\", \"%Y-%m-%d\")\n",
    "    \n",
    "    while len(unique_articles) < n:\n",
    "        formatted_date = date.strftime(\"%Y/%m/%d\")\n",
    "        articles = query(formatted_date)\n",
    "        \n",
    "        for article in articles:\n",
    "            unique_articles[article['article']] = article\n",
    "        \n",
    "        date -= timedelta(days=1)  # Passa al giorno precedente\n",
    "\n",
    "    # Prendi solo i primi n articoli\n",
    "    most_viewed_articles = list(unique_articles.values())[:n]\n",
    "    \n",
    "    return most_viewed_articles\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T22:46:19.971Z",
     "start_time": "2024-05-27T22:46:19.967733Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calcolo paginie più visitate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 10000 pages\n"
     ]
    }
   ],
   "source": [
    "# Esempio di utilizzo\n",
    "n = 10000  # Numero di pagine uniche richieste\n",
    "most_viewed_pages = most_viewed(n)\n",
    "print(f\"Fetched {len(most_viewed_pages)} pages\")\n",
    "\n",
    "entities = fetch_wikidata_ids(most_viewed_pages)\n",
    "entities_list = [str(element) for element in list(entities.values())]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T22:47:55.523312Z",
     "start_time": "2024-05-27T22:46:19.971973Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 out of 193\n",
      "Processing batch 2 out of 193\n",
      "Processing batch 3 out of 193\n",
      "Processing batch 4 out of 193\n",
      "Processing batch 5 out of 193\n",
      "Processing batch 6 out of 193\n",
      "Processing batch 7 out of 193\n",
      "Processing batch 8 out of 193\n",
      "Processing batch 9 out of 193\n",
      "Processing batch 10 out of 193\n",
      "Processing batch 11 out of 193\n",
      "Processing batch 12 out of 193\n",
      "Processing batch 13 out of 193\n",
      "Processing batch 14 out of 193\n",
      "Processing batch 15 out of 193\n",
      "Processing batch 16 out of 193\n",
      "Processing batch 17 out of 193\n",
      "Processing batch 18 out of 193\n",
      "Processing batch 19 out of 193\n",
      "Processing batch 20 out of 193\n",
      "Processing batch 21 out of 193\n",
      "Processing batch 22 out of 193\n",
      "Processing batch 23 out of 193\n",
      "Processing batch 24 out of 193\n",
      "Processing batch 25 out of 193\n",
      "Processing batch 26 out of 193\n",
      "Processing batch 27 out of 193\n",
      "Processing batch 28 out of 193\n",
      "Processing batch 29 out of 193\n",
      "Processing batch 30 out of 193\n",
      "Processing batch 31 out of 193\n",
      "Processing batch 32 out of 193\n",
      "Processing batch 33 out of 193\n",
      "Processing batch 34 out of 193\n",
      "Processing batch 35 out of 193\n",
      "Processing batch 36 out of 193\n",
      "Processing batch 37 out of 193\n",
      "Processing batch 38 out of 193\n",
      "Processing batch 39 out of 193\n",
      "Processing batch 40 out of 193\n",
      "Processing batch 41 out of 193\n",
      "Processing batch 42 out of 193\n",
      "Processing batch 43 out of 193\n",
      "Processing batch 44 out of 193\n",
      "Processing batch 45 out of 193\n",
      "Processing batch 46 out of 193\n",
      "Processing batch 47 out of 193\n",
      "Processing batch 48 out of 193\n",
      "Processing batch 49 out of 193\n",
      "Processing batch 50 out of 193\n",
      "Processing batch 51 out of 193\n",
      "Processing batch 52 out of 193\n",
      "Processing batch 53 out of 193\n",
      "Processing batch 54 out of 193\n",
      "Processing batch 55 out of 193\n",
      "Processing batch 56 out of 193\n",
      "Processing batch 57 out of 193\n",
      "Processing batch 58 out of 193\n",
      "Processing batch 59 out of 193\n",
      "Processing batch 60 out of 193\n",
      "Processing batch 61 out of 193\n",
      "Processing batch 62 out of 193\n",
      "Processing batch 63 out of 193\n",
      "Processing batch 64 out of 193\n",
      "Processing batch 65 out of 193\n",
      "Processing batch 66 out of 193\n",
      "Processing batch 67 out of 193\n",
      "Processing batch 68 out of 193\n",
      "Processing batch 69 out of 193\n",
      "Processing batch 70 out of 193\n",
      "Processing batch 71 out of 193\n",
      "Processing batch 72 out of 193\n",
      "Processing batch 73 out of 193\n",
      "Processing batch 74 out of 193\n",
      "Processing batch 75 out of 193\n",
      "Processing batch 76 out of 193\n",
      "Processing batch 77 out of 193\n",
      "Processing batch 78 out of 193\n",
      "Processing batch 79 out of 193\n",
      "Processing batch 80 out of 193\n",
      "Processing batch 81 out of 193\n",
      "Processing batch 82 out of 193\n",
      "Processing batch 83 out of 193\n",
      "Processing batch 84 out of 193\n",
      "Processing batch 85 out of 193\n",
      "Processing batch 86 out of 193\n",
      "Processing batch 87 out of 193\n",
      "Processing batch 88 out of 193\n",
      "Processing batch 89 out of 193\n",
      "Processing batch 90 out of 193\n",
      "Processing batch 91 out of 193\n",
      "Processing batch 92 out of 193\n",
      "Processing batch 93 out of 193\n",
      "Processing batch 94 out of 193\n",
      "Processing batch 95 out of 193\n",
      "Processing batch 96 out of 193\n",
      "Processing batch 97 out of 193\n",
      "Processing batch 98 out of 193\n",
      "Processing batch 99 out of 193\n",
      "Processing batch 100 out of 193\n",
      "Processing batch 101 out of 193\n",
      "Processing batch 102 out of 193\n",
      "Processing batch 103 out of 193\n",
      "Processing batch 104 out of 193\n",
      "Processing batch 105 out of 193\n",
      "Processing batch 106 out of 193\n",
      "Processing batch 107 out of 193\n",
      "Processing batch 108 out of 193\n",
      "Processing batch 109 out of 193\n",
      "Processing batch 110 out of 193\n",
      "Processing batch 111 out of 193\n",
      "Processing batch 112 out of 193\n",
      "Processing batch 113 out of 193\n",
      "Processing batch 114 out of 193\n",
      "Processing batch 115 out of 193\n",
      "Processing batch 116 out of 193\n",
      "Processing batch 117 out of 193\n",
      "Processing batch 118 out of 193\n",
      "Processing batch 119 out of 193\n",
      "Processing batch 120 out of 193\n",
      "Processing batch 121 out of 193\n",
      "Processing batch 122 out of 193\n",
      "Processing batch 123 out of 193\n",
      "Processing batch 124 out of 193\n",
      "Processing batch 125 out of 193\n",
      "Processing batch 126 out of 193\n",
      "Processing batch 127 out of 193\n",
      "Processing batch 128 out of 193\n",
      "Processing batch 129 out of 193\n",
      "Processing batch 130 out of 193\n",
      "Processing batch 131 out of 193\n",
      "Processing batch 132 out of 193\n",
      "Processing batch 133 out of 193\n",
      "Processing batch 134 out of 193\n",
      "Processing batch 135 out of 193\n",
      "Processing batch 136 out of 193\n",
      "Processing batch 137 out of 193\n",
      "Processing batch 138 out of 193\n",
      "Processing batch 139 out of 193\n",
      "Processing batch 140 out of 193\n",
      "Processing batch 141 out of 193\n",
      "Processing batch 142 out of 193\n",
      "Processing batch 143 out of 193\n",
      "Processing batch 144 out of 193\n",
      "Processing batch 145 out of 193\n",
      "Processing batch 146 out of 193\n",
      "Processing batch 147 out of 193\n",
      "Processing batch 148 out of 193\n",
      "Processing batch 149 out of 193\n",
      "Processing batch 150 out of 193\n",
      "Processing batch 151 out of 193\n",
      "Processing batch 152 out of 193\n",
      "Processing batch 153 out of 193\n",
      "Processing batch 154 out of 193\n",
      "Processing batch 155 out of 193\n",
      "Processing batch 156 out of 193\n",
      "Processing batch 157 out of 193\n",
      "Processing batch 158 out of 193\n",
      "Processing batch 159 out of 193\n",
      "Processing batch 160 out of 193\n",
      "Processing batch 161 out of 193\n",
      "Processing batch 162 out of 193\n",
      "Processing batch 163 out of 193\n",
      "Processing batch 164 out of 193\n",
      "Processing batch 165 out of 193\n",
      "Processing batch 166 out of 193\n",
      "Processing batch 167 out of 193\n",
      "Processing batch 168 out of 193\n",
      "Processing batch 169 out of 193\n",
      "Processing batch 170 out of 193\n",
      "Processing batch 171 out of 193\n",
      "Processing batch 172 out of 193\n",
      "Processing batch 173 out of 193\n",
      "Processing batch 174 out of 193\n",
      "Processing batch 175 out of 193\n",
      "Processing batch 176 out of 193\n",
      "Processing batch 177 out of 193\n",
      "Processing batch 178 out of 193\n",
      "Processing batch 179 out of 193\n",
      "Processing batch 180 out of 193\n",
      "Processing batch 181 out of 193\n",
      "Processing batch 182 out of 193\n",
      "Processing batch 183 out of 193\n",
      "Processing batch 184 out of 193\n",
      "Processing batch 185 out of 193\n",
      "Processing batch 186 out of 193\n",
      "Processing batch 187 out of 193\n",
      "Processing batch 188 out of 193\n",
      "Processing batch 189 out of 193\n",
      "Processing batch 190 out of 193\n",
      "Processing batch 191 out of 193\n",
      "Processing batch 192 out of 193\n",
      "Processing batch 193 out of 193\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "relations = get_relations_batch(entities_list)\n",
    "print(\"Processing complete.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T22:55:30.579985Z",
     "start_time": "2024-05-27T22:47:55.526765Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0mT7q-T1tzLd",
    "ExecuteTime": {
     "end_time": "2024-05-27T22:55:30.586666Z",
     "start_time": "2024-05-27T22:55:30.581627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Q122921105\n",
      "  Property: P31\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 11424, 'id': 'Q11424'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P345\n",
      "    Value: {'value': 'tt23849204', 'type': 'string'}\n",
      "  Property: P4947\n",
      "    Value: {'value': '1163258', 'type': 'string'}\n",
      "  Property: P6127\n",
      "    Value: {'value': '12th-fail', 'type': 'string'}\n",
      "  Property: P495\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 668, 'id': 'Q668'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P577\n",
      "    Value: {'value': {'time': '+2023-10-27T00:00:00Z', 'timezone': 0, 'before': 0, 'after': 0, 'precision': 11, 'calendarmodel': 'http://www.wikidata.org/entity/Q1985727'}, 'type': 'time'}\n",
      "  Property: P57\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 1607373, 'id': 'Q1607373'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P364\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 1568, 'id': 'Q1568'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P86\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 7489036, 'id': 'Q7489036'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P272\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 3560299, 'id': 'Q3560299'}, 'type': 'wikibase-entityid'}\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 55638217, 'id': 'Q55638217'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P161\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 2004189, 'id': 'Q2004189'}, 'type': 'wikibase-entityid'}\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 23712687, 'id': 'Q23712687'}, 'type': 'wikibase-entityid'}\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 7246522, 'id': 'Q7246522'}, 'type': 'wikibase-entityid'}\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 63346821, 'id': 'Q63346821'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P7573\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 74434526, 'id': 'Q74434526'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P8674\n",
      "    Value: {'value': '12th-fail', 'type': 'string'}\n",
      "  Property: P11049\n",
      "    Value: {'value': '1260161273', 'type': 'string'}\n",
      "  Property: P462\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 22006653, 'id': 'Q22006653'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P11460\n",
      "    Value: {'value': '63878b16c05d84ba8ef48e96', 'type': 'string'}\n",
      "  Property: P9586\n",
      "    Value: {'value': 'umc.cmc.22akjgefslahezpwegmoevdap', 'type': 'string'}\n",
      "  Property: P1258\n",
      "    Value: {'value': 'm/12th_fail', 'type': 'string'}\n",
      "  Property: P12683\n",
      "    Value: {'value': 'film/136877', 'type': 'string'}\n",
      "Entity: Q116003774\n",
      "  Property: P155\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 111812475, 'id': 'Q111812475'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P31\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 27020041, 'id': 'Q27020041'}, 'type': 'wikibase-entityid'}\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 64728935, 'id': 'Q64728935'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P641\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 131471, 'id': 'Q131471'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P664\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 1676131, 'id': 'Q1676131'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P3450\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 2634432, 'id': 'Q2634432'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P156\n",
      "    Value: {'value': {'entity-type': 'item', 'numeric-id': 124126744, 'id': 'Q124126744'}, 'type': 'wikibase-entityid'}\n",
      "  Property: P2671\n",
      "    Value: {'value': '/g/11tp2bnjlk', 'type': 'string'}\n"
     ]
    }
   ],
   "source": [
    "# Print out the relations\n",
    "limit = 1\n",
    "count = 0\n",
    "for wikidata_id, claims in relations.items():\n",
    "    if count<=limit:\n",
    "        count+=1\n",
    "        print(f\"Entity: {wikidata_id}\")\n",
    "        for property_id, claim_list in claims.items():\n",
    "            print(f\"  Property: {property_id}\")\n",
    "            for claim in claim_list:\n",
    "                mainsnak = claim['mainsnak']\n",
    "                if 'datavalue' in mainsnak:\n",
    "                    value = mainsnak['datavalue']\n",
    "                    print(f\"    Value: {value}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ED1sFI0Cxn3b",
    "ExecuteTime": {
     "end_time": "2024-05-27T22:55:31.015804Z",
     "start_time": "2024-05-27T22:55:30.587971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       entity   rel      objt\n0  Q122921105   P31    Q11424\n1  Q122921105  P495      Q668\n2  Q122921105   P57  Q1607373",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity</th>\n      <th>rel</th>\n      <th>objt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q122921105</td>\n      <td>P31</td>\n      <td>Q11424</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q122921105</td>\n      <td>P495</td>\n      <td>Q668</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q122921105</td>\n      <td>P57</td>\n      <td>Q1607373</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples = []\n",
    "\n",
    "for wikidata_id, claims in relations.items():\n",
    "    for property_id, claim_list in claims.items():\n",
    "        for claim in claim_list:\n",
    "            mainsnak = claim['mainsnak']\n",
    "            if 'datavalue' in mainsnak:\n",
    "                value = mainsnak['datavalue']\n",
    "                if value['type'] == 'wikibase-entityid':\n",
    "                    value_id = value['value']['id']\n",
    "                    #print(f\"Entity: {wikidata_id} Relation: {property_id} Entity: {value_id}\")\n",
    "                    triples.append({'entity': wikidata_id, 'rel': property_id, 'objt': value_id})\n",
    "\n",
    "# Crea il DataFrame dalle triple\n",
    "df = pd.DataFrame(triples)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NIrZHeiV2PgI",
    "ExecuteTime": {
     "end_time": "2024-05-27T22:55:31.099143Z",
     "start_time": "2024-05-27T22:55:31.016615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di entità (head) presenti: 9578\n",
      "Numero di relazioni presenti: 889\n",
      "Numero di entità (tail) presenti: 115338\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numero di entità (head) presenti: {df.entity.nunique()}\")\n",
    "print(f\"Numero di relazioni presenti: {df.rel.nunique()}\")\n",
    "print(f\"Numero di entità (tail) presenti: {df.objt.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(290901, 3)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T22:55:31.104965Z",
     "start_time": "2024-05-27T22:55:31.100817Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4eWHmi56r6Zk",
    "ExecuteTime": {
     "end_time": "2024-05-27T22:55:31.282856Z",
     "start_time": "2024-05-27T22:55:31.106673Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/df_triple.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
